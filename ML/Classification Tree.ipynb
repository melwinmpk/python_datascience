{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFICATION AND REGRESSION TREES (CART)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>CLASSIFICATION AND REGRESSION TREES (CART)</b> are binary decision trees, which split a single variable at each node.<br>\n",
    "–The CART algorithm recursively goes though an exhaustive search of all variables and split values to find the optimal splitting rule for each node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART Splitting Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/get-your-decision-tree-model-moving-by-cart-82765d59ae09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CART uses the Gini Index as measure of impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/700/1*jRf8Rw3NZewXp3us7aPb8Q.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>p(Ck|t) is the probability of a node t being the category Ck.</li>\n",
    "<li>The Gini coefficient of the node t is 1 minus the sum of the probability of all the categories.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gini Gain = Gini (Overall) – Gini (selected_Colum)\n",
    "reffer the Utkarsh PPt for more understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gini Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/melwinmpk/python_datascience/blob/main/ML/img/Gini_formula.png\">Gini Index Formula</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/melwinmpk/python_datascience/blob/04320aa6f52d50814d862d13b45ae1109aff6545/ML/img/GiniCalcluation.png\">Gini Calucation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Class rate</b>:In a Node the maximum Target value will be considered as Class rate <br>\n",
    "<b>Loss</b>:Loss is the number of cases mis- classified in a given node <br>\n",
    "<b>Mis-Classification Error</b>:Mis-Classification Error is the ratio of total number of cases mis- classified to total number of cases <br>– We are interested in mis- classification error for the full tree <br>\n",
    "<b>Response Rate</b> is the ratio of number of responders (Target =\n",
    "1)to the total number of cases <br> \n",
    "– We are interested in finding nodes where the response rate is very high <br>\n",
    "for example:<br>\n",
    "if the Node has <br>\n",
    "total observation => 14000 <br>\n",
    "target 1 => 1,235 <br> \n",
    "target 0 => 12,765 <br>\n",
    "So <b>Class Rate</b> will be <b> 0 </b> (Because the Target 0 count is maximum )<br>\n",
    "<b>Mis-Clasification error</b> will be 1,235/14000 <br>\n",
    "<b>Response Rate</b> is 1,235/14000 <br>\n",
    "<b>Loss</b> is 1,235 (as you see loss will be opposit of the Class Rate Target Value)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A greedy algorithm is a simple, intuitive algorithm that is used in optimization problems. The algorithm makes the optimal choice at each step as it attempts to find the overall optimal way to solve the entire problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " the greedy approach picks an immediate optimized solution and may fail where global optimization is a major concern.\n",
    " https://www.tutorialspoint.com/data_structures_algorithms/greedy_algorithms.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what is overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Pruning is a data compression technique in machine learning and search algorithms that reduces the size of decision trees by removing sections of the tree that are non-critical and redundant to classify instances.</li>\n",
    "<li>Pruning is Basically the average cost complexity reduced per leaf in a Decision Tree.</li>\n",
    "<li>Generally It’s a hit & try method to get the accuracy improved over the depth of tree getting reduced or average number of nodes reduced without over fitting.</li>\n",
    "<li>Practically, We creates a Tree structure which is getting refined on certain pre-assumptions for improving the performance and accuracy of a Decision Tree classifier</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is a summary of prediction results on a classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://glassboxmedicine.files.wordpress.com/2019/02/confusion-matrix.png?w=816\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy = (True Postives + True Negatives)/(Total no of observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under Curve\n",
    "https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC - ROC curve is a performance measurement for the classification problems at various threshold settings. ROC is a probability curve and AUC represents the degree or measure of separability.<br>\n",
    "It tells how much the model is capable of distinguishing between classes. Higher the AUC, the better the model is at predicting 0s as 0s and 1s as 1s.<br>\n",
    "By analogy, the Higher the AUC, the better the model is at distinguishing between patients with the disease and no disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/361/1*pk05QGzoWhCgRiiFbz-oKQ.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>TPR (True Positive Rate) / Recall /Sensitivity<b>\n",
    "<img src=\"https://miro.medium.com/max/355/1*HgxNKuUwXk9JHYBCt_KZNw.png\"></img>\n",
    "<b>Specificity</b>\n",
    "<img src=\"https://miro.medium.com/max/246/1*f7NmMcQtfes1ng7jtjNtHQ.png\"></img>\n",
    "<b>FPR (False Positive Rate)</b>\n",
    "<img src=\"https://miro.medium.com/max/245/1*3GhDfiuhvINF5-9eL8g6Pw.png\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
