{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAG of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The bag-of-words model is simple to understand and implement. It is a way of extracting features from the text for use in machine learning algorithms.\n",
    " \n",
    " In this approach, we use the tokenized words for each observation and find out the frequency of each token.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Drawback</b><br>\n",
    "Bag of words gives the equal weightage to all the words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "### Term Frequency and Inverse Document Frequency|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>TF-IDF is useful in solving the major drawbacks of Bag of words by introducing an important concept called inverse document frequency.\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "    <li><b>Tf</b> = No. of rep of words in sentence / no. of words in sentence</li>\n",
    "    <li><b>Idf</b> = log(no. of sentences/ no. Of  sentence containing words)</li>\n",
    "</ul>\n",
    "\n",
    "<p><b>TF answers questions like</b> â€” how many times is beauty(word) used in that entire document, give me a probability</p>\n",
    "<p><b>IDF answers questions like</b> - how important is the word beauty in the entire list of documents, is it a common theme in all the documents</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for example\n",
    "<p>lets consider 3 text Sentances</p>\n",
    "<ol>\n",
    "<li>\"Good Boy\"</li>\n",
    "<li>\"Good Girl\"</li>\n",
    "<li>\"Boy Good Girl\"</li>\n",
    "</ol>\n",
    "Bag of words will be = [\"Good\", \"Boy\", \"Girl\"]\n",
    "\n",
    "<b>TF will be</b>\n",
    "<p><b>Tf</b> = No. of rep of words in sentence / no. of words in sentence</p>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th></th>\n",
    "        <th>Sentance 1</th>\n",
    "        <th>Sentance 2</th>\n",
    "        <th>Sentance 3</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Good</th>\n",
    "        <td>1/2</td>\n",
    "        <td>1/2</td>\n",
    "        <td>1/3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Boy</th>\n",
    "        <td>1/2</td>\n",
    "        <td>0</td>\n",
    "        <td>1/3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Girl</th>\n",
    "        <td>0</td>\n",
    "        <td>1/2</td>\n",
    "        <td>1/3</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<b>IDF will be</b>\n",
    "<p><b>Idf</b> = log(no. of sentences/ no. Of  sentence containing words)</p>\n",
    "<ul>\n",
    "    <li><b>Good</b> = log(3/3) = 0</li>\n",
    "    <li><b>Boy</b> = log(3/2)</li>\n",
    "    <li><b>Girl</b> = log(3/2)</li>\n",
    "</ul>\n",
    "\n",
    "<p>Then <b>TF * IDF</b> will be</p>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th></th>\n",
    "        <th>Good </th>\n",
    "        <th>Boy </th>\n",
    "        <th>Girl</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Sentance 1</th>\n",
    "        <td>1/2 * log(3/3) = 0 </td>\n",
    "        <td>1/2 * log(3/2)</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Sentance 2</th>\n",
    "        <td>1/2 * log(3/3) = 0</td>\n",
    "        <td>0</td>\n",
    "        <td>1/2 * log(3/2) </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Sentance 3</th>\n",
    "        <td>1/3 * log(3/3) = 0 </td>\n",
    "        <td>1/3 * log(3/2)</td>\n",
    "        <td>1/3 * log(3/2)</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = '''I have three visions for India. In 3090 years of our history, people from all over\n",
    "               the world have come and invaded us, captured our lands, conquered our minds. \n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British, the French, \n",
    "               the Dutch, all of them cane and looted us, took over what was ours. Yet we have not done this to any \n",
    "               other nation. We have not conquered anyone. We have not grabbed their land, their culture, their \n",
    "               history and tried to enforce our way of life on them. Why? Because we respect the freedom of others. \n",
    "               That is why ny first vision is that of freedom. I believe that India got its first vision of this in 1857, \n",
    "               when we started the war of Independence. It is this freedom that we must protect and nurture and build on. \n",
    "               If we are not free, no one will respect us. My second vision for India's development. For fifty years we \n",
    "               have been a developing nation. It is time we see ourselves as a developed nation. We are among the top 5 \n",
    "               nations of the world in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty \n",
    "               levels are falling. Our achievements are being globally recognised today. \n",
    "               Yet we lack the self-confidence to see ourselves as a developed nation, self-reliant and self-assured. \n",
    "               Isn't this incorrect? I have a third vision. India must stand up to the world. \n",
    "               Because I believe that unless India stands up to the world, no one will respect us. \n",
    "               Only strength respects strength. We must be strong not only as a military power \n",
    "               but also as an economic power. Both must go hand-in-hand. My good fortune was to have \n",
    "               worked with three great minds. Dr. Vikram Sarabhai of the Dept. of space, Professor Satish Dhawan, \n",
    "               who succeeded him and Dr. Brahm Prakash, father of nuclear material. I was lucky to have worked \n",
    "               with all three of them closely and consider this the great opportunity of my life. \n",
    "               I see four milestones in my career'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\melwin\\.conda\\envs\\tutorialdatascience\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\melwin\\.conda\\envs\\tutorialdatascience\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "c:\\users\\melwin\\.conda\\envs\\tutorialdatascience\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Melwin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Error loading stopwrods: Package 'stopwrods' not found in\n",
      "[nltk_data]     index\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt') \n",
    "nltk.download('stopwrods')\n",
    "ps = PorterStemmer() \n",
    "wordnet = WordNetLemmatizer()\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "# aim to clean the data\n",
    "corpus = []\n",
    "'''\n",
    "1. lowercase \n",
    "2. word tokensize \n",
    "3. renove stopwords \n",
    "4. stem / lemmatize\n",
    "'''\n",
    "for i in range(len( sentences)):\n",
    "    review = re.sub( '^-ZA-Z]', ' ',sentences[i]) \n",
    "    review = review.lower() \n",
    "    review = review.split() # word tokenize \n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))] \n",
    "    reveiw = \" \".join(review) \n",
    "    corpus.append(reveiw)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a bow model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer() \n",
    "x = cv.fit_transform(corpus).toarray()\n",
    "\n",
    "feature_names = cv.get_feature_names()\n",
    "from sklearn. feature_extraction.text import TfidfVectorizer\n",
    "CV = TfidfVectorizer() \n",
    "x_tfidf = cv.fit_transform(corpus).toarray()\n",
    "feature_names = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
